{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothetical dataset\n",
    "data = {'text': ['This is a real news article.', 'This is a fake news article.', 'Another real news article.'],\n",
    "        'label': [1, 0, 1]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning - TF-IDF feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sazgar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning - LSTM model\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_sequence_length = max([len(sequence) for sequence in X_train_sequences])\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length))\n",
    "model.add(LSTM(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning and Deep Learning fusion\n",
    "ensemble_model = Sequential()\n",
    "ensemble_model.add(Concatenate([model, LogisticRegression()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_padded_list = np.array(X_train_padded_list)\n",
    "X_train_tfidf_list = np.array(X_train_tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\ML\\detecting fake news\\detecting fake news.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Add an embedding layer to your model for each input\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embedding_layer \u001b[39m=\u001b[39m Embedding(max_features, \u001b[39m32\u001b[39m, input_length\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39madd(embedding_layer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Use the Embedding layer instead of the input layer in the next layer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# For example:\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# model.add(Conv1D(64, 3, activation='relu'))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/ML/detecting%20fake%20news/detecting%20fake%20news.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Add another embedding layer for the tfidf input\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'max_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Add an embedding layer to your model for each input\n",
    "embedding_layer = Embedding(max_features, 32, input_length=6)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "# Use the Embedding layer instead of the input layer in the next layer\n",
    "# For example:\n",
    "# model.add(Conv1D(64, 3, activation='relu'))\n",
    "\n",
    "# Add another embedding layer for the tfidf input\n",
    "embedding_layer_tfidf = Embedding(max_features, 32, input_length=4)\n",
    "model.add(embedding_layer_tfidf)\n",
    "\n",
    "# Use the second Embedding layer instead of the input layer in the next layer\n",
    "# For example:\n",
    "# model.add(Conv1D(64, 3, activation='relu'))\n",
    "\n",
    "# Finally, add the Concatenate layer\n",
    "concatenate_layer = Concatenate(axis=-1)\n",
    "model.add(concatenate_layer)\n",
    "\n",
    "# The rest of your code remains the same\n",
    "...\n",
    "loss, accuracy = model.evaluate(inputs, y_test, verbose=2)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
